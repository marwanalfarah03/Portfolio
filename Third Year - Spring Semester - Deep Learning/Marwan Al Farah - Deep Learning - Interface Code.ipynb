{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPo7Ki4UcY09"
      },
      "source": [
        "<br>\n",
        "\n",
        "<center><img src=\"https://www.htu.edu.jo/images/ThumbnailsCoverPhotos/HTU%20Logo-250px.png\" alt=\"HTU\"  width=\"180px\" align=\"center\">\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<p>\n",
        "\n",
        "**Deep Learning**\n",
        "\n",
        "10204450\n",
        "\n",
        "Section (3)\n",
        "\n",
        "**Developing a deep learning-based system - Interface**\n",
        "\n",
        "**Submitted to**\n",
        "\n",
        "Dr. Ala'a Al-Habashna\n",
        "\n",
        "**Submitted on**\n",
        "\n",
        "June 13th, 2024\n",
        "\n",
        "**Submitted by**\n",
        "\n",
        "Marwan Tarek Shafiq Al Farah\n",
        "\n",
        "**Student ID**\n",
        "\n",
        "21110011\n",
        "\n",
        "Spring 2023 â€“ 2024\n",
        "</p></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPYr2_xccvt"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XLQSZaQzcVYU"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox, Toplevel, Text\n",
        "from PIL import Image, ImageTk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-9L9EJ8cm6P"
      },
      "source": [
        "# **Models' Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QRHyXeRacVYV",
        "outputId": "d9755891-3357-49bb-fd5a-d175d3b2e8da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marwa\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\marwa\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "models_dict = {\n",
        "    'resnet18': models.resnet18(pretrained=False),\n",
        "    'vgg16': models.vgg16(pretrained=False),\n",
        "    'densenet121': models.densenet121(pretrained=False),\n",
        "    'mobilenet_v2': models.mobilenet_v2(pretrained=False)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rj-xgxIMcVYW"
      },
      "outputs": [],
      "source": [
        "num_classes = 14\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    if 'resnet' in model_name:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    elif 'vgg' in model_name:\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "    elif 'densenet' in model_name:\n",
        "        num_ftrs = model.classifier.in_features\n",
        "        model.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "    elif 'mobilenet' in model_name:\n",
        "        num_ftrs = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(num_ftrs, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tYGt8nzpcVYW"
      },
      "outputs": [],
      "source": [
        "model_paths = {\n",
        "    'resnet18': 'D:/Marwan/HTU/Third Year/Spring Semester/Deep Learning/My Solutions/Final/Deep Learning Outputs/best_resnet18.pth',\n",
        "    'vgg16': 'D:/Marwan/HTU/Third Year/Spring Semester/Deep Learning/My Solutions/Final/Deep Learning Outputs/best_vgg16.pth',\n",
        "    'densenet121': 'D:/Marwan/HTU/Third Year/Spring Semester/Deep Learning/My Solutions/Final/Deep Learning Outputs/best_densenet121.pth',\n",
        "    'mobilenet_v2': 'D:/Marwan/HTU/Third Year/Spring Semester/Deep Learning/My Solutions/Final/Deep Learning Outputs/best_mobilenet_v2.pth'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6KhtcN0mcVYX"
      },
      "outputs": [],
      "source": [
        "for model_name, model_path in model_paths.items():\n",
        "    models_dict[model_name].load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    models_dict[model_name].eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WR8j9OcsPp"
      },
      "source": [
        "# **Image Transform and Class Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pl1zJ0ehcVYX"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "th4wR96QcVYX"
      },
      "outputs": [],
      "source": [
        "# Map class indices to class names\n",
        "class_labels = {\n",
        "    0: 'cables',\n",
        "    1: 'case',\n",
        "    2: 'cpu',\n",
        "    3: 'gpu',\n",
        "    4: 'hdd',\n",
        "    5: 'headset',\n",
        "    6: 'keyboard',\n",
        "    7: 'microphone',\n",
        "    8: 'monitor',\n",
        "    9: 'motherboard',\n",
        "    10: 'mouse',\n",
        "    11: 'ram',\n",
        "    12: 'speakers',\n",
        "    13: 'webcam'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9yimfozcxCr"
      },
      "source": [
        "# **Interface Class Definitions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL6Su_ZAc92M"
      },
      "source": [
        "## **Initial Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D6SukbfZcVYX"
      },
      "outputs": [],
      "source": [
        "class InitialInterface:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"Initial Interface\")\n",
        "\n",
        "        self.run_test_button = tk.Button(root, text=\"Run on Entire Testing Set\", command=self.run_on_entire_testing_set)\n",
        "        self.run_test_button.pack(pady=20)\n",
        "\n",
        "        self.run_selected_button = tk.Button(root, text=\"Run on Selected Images\", command=self.run_on_selected_images)\n",
        "        self.run_selected_button.pack(pady=20)\n",
        "\n",
        "    def run_on_entire_testing_set(self):\n",
        "        self.root.destroy()\n",
        "        self.open_entire_testing_set_interface()\n",
        "\n",
        "    def run_on_selected_images(self):\n",
        "        self.root.destroy()\n",
        "        self.open_selected_images_interface()\n",
        "\n",
        "    def open_entire_testing_set_interface(self):\n",
        "        new_root = tk.Tk()\n",
        "        new_root.title(\"Run on Entire Testing Set\")\n",
        "        TestingSetApp(new_root)\n",
        "        new_root.protocol(\"WM_DELETE_WINDOW\", lambda: self.reopen_initial_interface(new_root))\n",
        "        new_root.mainloop()\n",
        "\n",
        "    def open_selected_images_interface(self):\n",
        "        new_root = tk.Tk()\n",
        "        app = ImageClassifierApp(new_root)\n",
        "        new_root.protocol(\"WM_DELETE_WINDOW\", lambda: self.reopen_initial_interface(new_root))\n",
        "        new_root.mainloop()\n",
        "\n",
        "    def reopen_initial_interface(self, window):\n",
        "        window.destroy()\n",
        "        root = tk.Tk()\n",
        "        InitialInterface(root)\n",
        "        root.mainloop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO6w1Z1ldAxZ"
      },
      "source": [
        "## **Testing Dataset Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QdmfBmSxcVYX"
      },
      "outputs": [],
      "source": [
        "class TestingSetApp:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"Run on Entire Testing Set\")\n",
        "\n",
        "        self.model_name = tk.StringVar(value='resnet18')\n",
        "\n",
        "        # Dropdown menu to select the model\n",
        "        self.model_label = tk.Label(root, text=\"Select Model:\")\n",
        "        self.model_label.pack()\n",
        "        self.model_menu = tk.OptionMenu(root, self.model_name, *models_dict.keys())\n",
        "        self.model_menu.pack()\n",
        "\n",
        "        # Button to run predictions on the entire testing set\n",
        "        self.run_button = tk.Button(root, text=\"Run Predictions\", command=self.run_predictions)\n",
        "        self.run_button.pack(pady=20)\n",
        "\n",
        "        # Buttons for classification report and confusion matrix\n",
        "        self.report_button = tk.Button(root, text=\"Show Classification Report\", command=self.show_report, state=tk.DISABLED)\n",
        "        self.report_button.pack(pady=5)\n",
        "        self.confusion_matrix_button = tk.Button(root, text=\"Show Confusion Matrix\", command=self.show_confusion_matrix, state=tk.DISABLED)\n",
        "        self.confusion_matrix_button.pack(pady=5)\n",
        "\n",
        "        # Navigation buttons\n",
        "        self.prev_button = tk.Button(root, text=\"Previous\", command=self.show_prev_image, state=tk.DISABLED)\n",
        "        self.prev_button.pack(side=tk.LEFT)\n",
        "        self.next_button = tk.Button(root, text=\"Next\", command=self.show_next_image, state=tk.DISABLED)\n",
        "        self.next_button.pack(side=tk.RIGHT)\n",
        "\n",
        "        # Label to show the selected image\n",
        "        self.image_label = tk.Label(root)\n",
        "        self.image_label.pack()\n",
        "\n",
        "        # Labels to show prediction results\n",
        "        self.correct_label = tk.Label(root, text=\"\")\n",
        "        self.correct_label.pack()\n",
        "        self.actual_class_label = tk.Label(root, text=\"\")\n",
        "        self.actual_class_label.pack()\n",
        "        self.predicted_class_label = tk.Label(root, text=\"\")\n",
        "        self.predicted_class_label.pack()\n",
        "\n",
        "        # Variables to store images and predictions\n",
        "        self.images = []\n",
        "        self.predictions = []\n",
        "        self.actual_classes = []\n",
        "        self.current_image_index = 0\n",
        "\n",
        "        # Load the dataset\n",
        "        self.dataset = datasets.ImageFolder(root='D:/Marwan/HTU/Third Year/Spring Semester/Deep Learning/My Solutions/Final/pc_parts', transform=transform)\n",
        "        train_size = int(0.7 * len(self.dataset))\n",
        "        val_size = int(0.15 * len(self.dataset))\n",
        "        test_size = len(self.dataset) - train_size - val_size\n",
        "        torch.manual_seed(42)\n",
        "        _, _, self.dataset = random_split(self.dataset, [train_size, val_size, test_size])\n",
        "        self.dataloader = DataLoader(self.dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    def run_predictions(self):\n",
        "        self.images = []\n",
        "        self.predictions = []\n",
        "        self.actual_classes = []\n",
        "        self.current_image_index = 0\n",
        "\n",
        "        model = models_dict[self.model_name.get()]\n",
        "\n",
        "        for inputs, labels in self.dataloader:\n",
        "            image = inputs.squeeze(0)\n",
        "            self.images.append(image)\n",
        "            actual_class = class_labels[labels.item()]\n",
        "            self.actual_classes.append(actual_class)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                predicted_class = class_labels[preds.item()]\n",
        "                self.predictions.append(predicted_class)\n",
        "\n",
        "        self.show_image()\n",
        "        self.update_buttons()\n",
        "        self.report_button.config(state=tk.NORMAL)\n",
        "        self.confusion_matrix_button.config(state=tk.NORMAL)\n",
        "\n",
        "    def show_image(self):\n",
        "        if not self.images:\n",
        "            return\n",
        "        image = self.images[self.current_image_index]\n",
        "        image = transforms.ToPILImage()(image)\n",
        "        image.thumbnail((200, 200))\n",
        "        self.image = ImageTk.PhotoImage(image)\n",
        "        self.image_label.config(image=self.image)\n",
        "\n",
        "        if self.predictions[self.current_image_index] == self.actual_classes[self.current_image_index]:\n",
        "            self.correct_label.config(text=\"Correctly Classified\")\n",
        "        else:\n",
        "            self.correct_label.config(text=\"Misclassified\")\n",
        "\n",
        "        self.actual_class_label.config(text=f\"Actual Class: {self.actual_classes[self.current_image_index]}\")\n",
        "        self.predicted_class_label.config(text=f\"Predicted Class: {self.predictions[self.current_image_index]}\")\n",
        "        self.update_buttons()\n",
        "\n",
        "    def update_buttons(self):\n",
        "        if self.current_image_index == 0:\n",
        "            self.prev_button.config(state=tk.DISABLED)\n",
        "        else:\n",
        "            self.prev_button.config(state=tk.NORMAL)\n",
        "        if self.current_image_index == len(self.images) - 1:\n",
        "            self.next_button.config(state=tk.DISABLED)\n",
        "        else:\n",
        "            self.next_button.config(state=tk.NORMAL)\n",
        "\n",
        "    def show_prev_image(self):\n",
        "        if self.current_image_index > 0:\n",
        "            self.current_image_index -= 1\n",
        "            self.show_image()\n",
        "\n",
        "    def show_next_image(self):\n",
        "        if self.current_image_index < len(self.images) - 1:\n",
        "            self.current_image_index += 1\n",
        "            self.show_image()\n",
        "\n",
        "    def show_report(self):\n",
        "        report = classification_report(self.actual_classes, self.predictions, target_names=[class_labels[i] for i in range(num_classes)])\n",
        "        report_window = Toplevel(self.root)\n",
        "        report_window.title(\"Classification Report\")\n",
        "        report_text = Text(report_window, wrap=tk.WORD)\n",
        "        report_text.pack(expand=True, fill=tk.BOTH)\n",
        "        report_text.insert(tk.END, report)\n",
        "\n",
        "    def show_confusion_matrix(self):\n",
        "        cm = confusion_matrix(self.actual_classes, self.predictions)\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm_window = Toplevel(self.root)\n",
        "        cm_window.title(\"Confusion Matrix\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        sns.heatmap(cm_normalized, annot=True, cmap=\"Blues\", xticklabels=[class_labels[i] for i in range(num_classes)], yticklabels=[class_labels[i] for i in range(num_classes)], ax=ax)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Confusion Matrix')\n",
        "\n",
        "        canvas = FigureCanvasTkAgg(fig, master=cm_window)\n",
        "        canvas.draw()\n",
        "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fhKjF5wdFBS"
      },
      "source": [
        "## **Image Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0RNy5Jd8cVYY"
      },
      "outputs": [],
      "source": [
        "class ImageClassifierApp:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"Image Classifier\")\n",
        "\n",
        "        self.model_name = tk.StringVar(value='resnet18')\n",
        "\n",
        "        # Dropdown menu to select the model\n",
        "        self.model_label = tk.Label(root, text=\"Select Model:\")\n",
        "        self.model_label.pack()\n",
        "        self.model_menu = tk.OptionMenu(root, self.model_name, *models_dict.keys())\n",
        "        self.model_menu.pack()\n",
        "\n",
        "        # Button to browse image\n",
        "        self.browse_button = tk.Button(root, text=\"Browse Images\", command=self.browse_images)\n",
        "        self.browse_button.pack()\n",
        "\n",
        "        # Label to show the selected image\n",
        "        self.image_label = tk.Label(root)\n",
        "        self.image_label.pack()\n",
        "\n",
        "        # Button to predict\n",
        "        self.predict_button = tk.Button(root, text=\"Predict\", command=self.predict)\n",
        "        self.predict_button.pack()\n",
        "\n",
        "        # Navigation buttons\n",
        "        self.prev_button = tk.Button(root, text=\"Previous\", command=self.show_prev_image, state=tk.DISABLED)\n",
        "        self.prev_button.pack(side=tk.LEFT)\n",
        "        self.next_button = tk.Button(root, text=\"Next\", command=self.show_next_image, state=tk.DISABLED)\n",
        "        self.next_button.pack(side=tk.RIGHT)\n",
        "\n",
        "        # Label to show the prediction result\n",
        "        self.result_label = tk.Label(root, text=\"\")\n",
        "        self.result_label.pack()\n",
        "\n",
        "        # Variables to store images and predictions\n",
        "        self.images = []\n",
        "        self.image_paths = []\n",
        "        self.current_image_index = 0\n",
        "\n",
        "    def browse_images(self):\n",
        "        self.filepaths = filedialog.askopenfilenames(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
        "        if not self.filepaths:\n",
        "            return\n",
        "        self.images = [Image.open(filepath) for filepath in self.filepaths]\n",
        "        self.image_paths = self.filepaths\n",
        "        self.current_image_index = 0\n",
        "        self.show_image()\n",
        "\n",
        "    def show_image(self):\n",
        "        image = self.images[self.current_image_index]\n",
        "        image.thumbnail((200, 200))\n",
        "        self.image = ImageTk.PhotoImage(image)\n",
        "        self.image_label.config(image=self.image)\n",
        "        self.result_label.config(text=\"\")\n",
        "        self.update_buttons()\n",
        "\n",
        "    def update_buttons(self):\n",
        "        if self.current_image_index == 0:\n",
        "            self.prev_button.config(state=tk.DISABLED)\n",
        "        else:\n",
        "            self.prev_button.config(state=tk.NORMAL)\n",
        "        if self.current_image_index == len(self.images) - 1:\n",
        "            self.next_button.config(state=tk.DISABLED)\n",
        "        else:\n",
        "            self.next_button.config(state=tk.NORMAL)\n",
        "\n",
        "    def show_prev_image(self):\n",
        "        if self.current_image_index > 0:\n",
        "            self.current_image_index -= 1\n",
        "            self.show_image()\n",
        "            self.result_label.config(text=f\"Predicted Class: {self.predictions[self.current_image_index]}\")\n",
        "\n",
        "    def show_next_image(self):\n",
        "        if self.current_image_index < len(self.images) - 1:\n",
        "            self.current_image_index += 1\n",
        "            self.show_image()\n",
        "            self.result_label.config(text=f\"Predicted Class: {self.predictions[self.current_image_index]}\")\n",
        "\n",
        "    def predict(self):\n",
        "        if not self.filepaths:\n",
        "            messagebox.showerror(\"Error\", \"Please select images first.\")\n",
        "            return\n",
        "\n",
        "        model = models_dict[self.model_name.get()]\n",
        "        self.predictions = []\n",
        "\n",
        "        for filepath in self.filepaths:\n",
        "            image = Image.open(filepath).convert('RGB')\n",
        "            image = transform(image)\n",
        "            image = image.unsqueeze(0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                predicted_class = class_labels[preds.item()]\n",
        "                self.predictions.append(predicted_class)\n",
        "\n",
        "        self.show_image()\n",
        "        self.result_label.config(text=f\"Predicted Class: {self.predictions[self.current_image_index]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_fu8nmBdKGg"
      },
      "source": [
        "# **Main Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yEAB05j2cVYY",
        "outputId": "7c86db08-228c-448a-d713-19aa78671318"
      },
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "InitialInterface(root)\n",
        "root.mainloop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AIPYr2_xccvt",
        "n-9L9EJ8cm6P",
        "14WR8j9OcsPp",
        "a9yimfozcxCr",
        "QL6Su_ZAc92M",
        "PO6w1Z1ldAxZ",
        "6fhKjF5wdFBS",
        "A_fu8nmBdKGg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
